{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3098ba5e-af25-4c7d-8478-bb179971fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aeb3c0-683d-4ce7-884d-9a5014e238eb",
   "metadata": {},
   "source": [
    "##  Token level features\n",
    "- The full constituent starting from a head word\n",
    "- The head of each token\n",
    "- The dependent(s) of each token\n",
    "- The Syntactic dependency relation from each token\n",
    "- Part-of-speech tag of each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "149f74ab-82b6-4488-9bde-7a76b16fa6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/article.txt\"\n",
    "\n",
    "with open(data_path, encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(content)\n",
    "\n",
    "token = [tok for tok in doc]\n",
    "constituent = [[t.text for t in tok.subtree] for tok in doc]  # The full constituent starting from a head word\n",
    "head = [tok.head for tok in doc]  # The head of each token\n",
    "dependent = [[t.text for t in tok.children] for tok in doc]  # The dependent(s) of each token\n",
    "dependency = [tok.dep_ for tok in doc]  # The Syntactic dependency relation from each token\n",
    "pos = [tok.pos_ for tok in doc]  # Part-of-speech tag of each token\n",
    "\n",
    "result = pd.DataFrame({\"token\": token, \"constituent\": constituent, \"head\": head, \"dependent\": dependent, \"dependency\": dependency, \"POS\": pos})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "094a5088-34a3-48bd-aa6b-58f67d50ff47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>constituent</th>\n",
       "      <th>head</th>\n",
       "      <th>dependent</th>\n",
       "      <th>dependency</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Universities</td>\n",
       "      <td>[Universities, in, the, Netherlands]</td>\n",
       "      <td>looking</td>\n",
       "      <td>[in]</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in</td>\n",
       "      <td>[in, the, Netherlands]</td>\n",
       "      <td>Universities</td>\n",
       "      <td>[Netherlands]</td>\n",
       "      <td>prep</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>[the]</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>[]</td>\n",
       "      <td>det</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          token                           constituent          head  \\\n",
       "0  Universities  [Universities, in, the, Netherlands]       looking   \n",
       "1            in                [in, the, Netherlands]  Universities   \n",
       "2           the                                 [the]   Netherlands   \n",
       "\n",
       "       dependent dependency   POS  \n",
       "0           [in]      nsubj  NOUN  \n",
       "1  [Netherlands]       prep   ADP  \n",
       "2             []        det   DET  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:3]  # Example of the first 3 lines of the feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19893186-1454-467b-a301-8d4dfc533c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('data/token-level-features.conll', sep='\\t', index=False)  # Save as the corresponding conll file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c82235-8ecc-44f4-936b-cfd0cae36927",
   "metadata": {},
   "source": [
    "## Sentence level features\n",
    "- Shortest Dependency Path of each sentence\n",
    "- The length of Shortest Dependency Path of each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c83f06c0-deca-44d7-9ed0-5cdda66cadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = nltk.tokenize.sent_tokenize(content)\n",
    "path_list = []\n",
    "length_list = []\n",
    "\n",
    "for sentence in sentence_list:\n",
    "    edges = []\n",
    "    doc = nlp(sentence)\n",
    "    subject = [tok for tok in doc if (tok.dep_ == \"nsubj\")]\n",
    "    direct_object = [tok for tok in doc if (tok.dep_ == \"dobj\")]\n",
    "    if (len(direct_object) < 1) or (len(subject) < 1):\n",
    "        path_list.append(None)\n",
    "        length_list.append(None)\n",
    "        continue\n",
    "    else:\n",
    "        subject = subject[0]\n",
    "        direct_object = direct_object[0]\n",
    "        for token in doc:\n",
    "            for child in token.children:\n",
    "                edges.append(('{0}'.format(token.lower_),\n",
    "                                  '{0}'.format(child.lower_)))\n",
    "        graph = nx.Graph(edges)\n",
    "        entity1 = str(subject).lower()\n",
    "        entity2 = str(direct_object).lower()\n",
    "        shortest_path = nx.shortest_path(graph, source=entity1, target=entity2)\n",
    "        length = nx.shortest_path_length(graph, source=entity1, target=entity2)\n",
    "        path_list.append(shortest_path)\n",
    "        length_list.append(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1f091e5-6110-4b1f-a15b-157a43137337",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\"sentence\": sentence_list, \"shortest_dep_path\": path_list, \"shortest_path_length\": length_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a7dae4f-a98a-4977-8c75-96d30012d348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>shortest_dep_path</th>\n",
       "      <th>shortest_path_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Universities in the Netherlands are looking for ways to demonstrate when students are guilty of using ChatGPT, software that uses artificial intelligence to write pieces of text.</td>\n",
       "      <td>[universities, looking, are, guilty, of, using, software]</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Institutions said that text written by the program can be classified as academic fraud, but it is still difficult to prove, representatives of several universities told ANP.</td>\n",
       "      <td>[institutions, said, told, anp]</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If students have not written something themselves, they are not allowed to present it as self-made work, explained the University of Twente.</td>\n",
       "      <td>[students, written, something]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                             sentence  \\\n",
       "0  Universities in the Netherlands are looking for ways to demonstrate when students are guilty of using ChatGPT, software that uses artificial intelligence to write pieces of text.   \n",
       "1       Institutions said that text written by the program can be classified as academic fraud, but it is still difficult to prove, representatives of several universities told ANP.   \n",
       "2                                        If students have not written something themselves, they are not allowed to present it as self-made work, explained the University of Twente.   \n",
       "\n",
       "                                           shortest_dep_path  \\\n",
       "0  [universities, looking, are, guilty, of, using, software]   \n",
       "1                            [institutions, said, told, anp]   \n",
       "2                             [students, written, something]   \n",
       "\n",
       "   shortest_path_length  \n",
       "0                   6.0  \n",
       "1                   3.0  \n",
       "2                   2.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "results[:3]  # Example of the first 3 lines of the feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c54c2d0-a698-4356-bbb0-23461b282bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('data/sentence-level-features.conll', sep='\\t', index=False)  # Save as the corresponding conll file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hlt_env",
   "language": "python",
   "name": "hlt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
